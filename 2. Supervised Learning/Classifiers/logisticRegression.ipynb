{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(filename):\n",
    "    with open(filename,'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for i in range(len(dataset)):\n",
    "            dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mins = np.min(X,axis=0)\n",
    "    maxs = np.max(X,axis=0)\n",
    "    rng = maxs-mins\n",
    "    norm_X = 1-((maxs-X)/rng)\n",
    "    return norm_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_func(beta,X):\n",
    "    return 1.0/(1+np.exp(-np.dot(np.squeeze(np.matrix(beta.T)),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gradient(beta,X,y):\n",
    "    first_calc = logistic_func(beta, X)-y.reshape(X.shape[0],-1)\n",
    "    final_calc = np.dot(first_calc.T,X)\n",
    "    return final_calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(beta,X,y):\n",
    "    log_func_v = logistic_func(beta,X)\n",
    "    y = np.squeeze(y)\n",
    "    step1 = np.dot(y,np.log(log_func_v))\n",
    "    step2 = np.dot((1-y),np.log(1-log_func_v))\n",
    "    final = -step1 -step2\n",
    "    return np.mean(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desc(X,y,beta, lr=0.01,converge_change=0.001):\n",
    "    cost = cost_function(beta, X, y)\n",
    "    change_cost = 1\n",
    "    num_iter = 1\n",
    "    while(change_cost>converge_change):\n",
    "        old_cost = cost\n",
    "        beta = beta - (lr*log_gradient(beta,X,y))\n",
    "        cost = cost_func(beta,X,y)\n",
    "        change_cost = old_cost - cost\n",
    "        num_iter+=1\n",
    "    return beta,num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_values(beta,X):\n",
    "    pred_prob = logistic_func(beta, X)\n",
    "    pred_values = np.where(pred_prob>=.5,1,0)\n",
    "    return np.squeeze(pred_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg(X,y,beta):\n",
    "    x_0 = X[np.where(y==0.0)]\n",
    "    x_1 = X[np.where(y==1.0)]\n",
    "    plt.scatter([x_0[:,1],x_0[:,2]],c='b',label='y=0')\n",
    "    plt.scatter([x_1[:,1],x_1[:,2]],c='r',label='y=1')\n",
    "    x1=np.arrange(0,1,0.1)\n",
    "    x2 = -(beta[0,0]+beta[0,1]*x1)\n",
    "    plt.plot(x1,x2,c='k',label=\"Reg line\")\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,100) and (1,3) not aligned: 100 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [59], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m y\u001b[39m=\u001b[39mdataset[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m beta \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatrix(np\u001b[39m.\u001b[39mzeros(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[1;32m----> 8\u001b[0m beta,num_iter \u001b[39m=\u001b[39m gradient_desc(X, y, beta)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEstimated Regression Coefficient: \u001b[39m\u001b[39m\"\u001b[39m,beta)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo of iterations: \u001b[39m\u001b[39m\"\u001b[39m,num_iter)\n",
      "Cell \u001b[1;32mIn [56], line 2\u001b[0m, in \u001b[0;36mgradient_desc\u001b[1;34m(X, y, beta, lr, converge_change)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient_desc\u001b[39m(X,y,beta, lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,converge_change\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     cost \u001b[39m=\u001b[39m cost_function(beta, X, y)\n\u001b[0;32m      3\u001b[0m     change_cost \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      4\u001b[0m     num_iter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn [55], line 4\u001b[0m, in \u001b[0;36mcost_function\u001b[1;34m(beta, X, y)\u001b[0m\n\u001b[0;32m      2\u001b[0m log_func_v \u001b[39m=\u001b[39m logistic_func(beta,X)\n\u001b[0;32m      3\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(y)\n\u001b[1;32m----> 4\u001b[0m step1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(y,np\u001b[39m.\u001b[39;49mlog(log_func_v))\n\u001b[0;32m      5\u001b[0m step2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot((\u001b[39m1\u001b[39m\u001b[39m-\u001b[39my),np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mlog_func_v))\n\u001b[0;32m      6\u001b[0m final \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mstep1 \u001b[39m-\u001b[39mstep2\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,100) and (1,3) not aligned: 100 (dim 1) != 1 (dim 0)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = loadCSV(r'C:\\Users\\DELL\\Desktop\\AI ML\\DATA SETS\\\\logisticRegressionDataset.csv')\n",
    "    dataset = np.squeeze(np.matrix(dataset))\n",
    "    X=normalize(dataset[:,:-1])\n",
    "    X=np.hstack((np.matrix(np.ones(X.shape[0])).T,X))\n",
    "    y=dataset[:,-1]\n",
    "    beta = np.matrix(np.zeros(X.shape[0]))\n",
    "    beta,num_iter = gradient_desc(X, y, beta)\n",
    "    print(\"Estimated Regression Coefficient: \",beta)\n",
    "    print(\"No of iterations: \",num_iter)\n",
    "    y_pred = pred_values(beta, X)\n",
    "    print(\"Correctly predicted labels: \",np.sum(y==y_pred))\n",
    "    plot_reg(X, y, beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c1f741a4f83aa020b4b2a4d7353a073a4e5e4a855a3258a20da40294ddbf005"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
